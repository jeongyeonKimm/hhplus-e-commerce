# 선착순 쿠폰 발급 성능 테스트

## 1. 개요
이커머스 서비스에서는 선착순 쿠폰 발급 행사, 한정판 상품 판매와 같은 이벤트를 통해 짧은 시간 내에 급격한 트래픽 증가가 자주 발생한다. 
이러한 스파이크성 트래픽은 순간적으로 시스템에 과도한 부하를 가하여, 성능 저하나 심각할 경우 서비스 중단까지 초래할 수 있다.
트래픽 급증 상황에 대응하기 위해 캐싱, 데이터베이스 인덱싱, 이벤트 브로커(Kafka) 등의 기술을 활용하고 있다. 
따라서 이번 보고서에서는 **적절한 부하 테스트(K6)** 를 통해 다음 사항을 검증하고자 한다:
- 스파이크 트래픽 상황에서 이벤트 브로커가 의도한 대로 작동하는지 여부
- 트래픽 집중 구간에서의 병목 발생 위치 및 성능 저하 정도
- 시스템의 최대 처리 한계 및 안정성 수준

이를 통해 실제 운영 환경에서 발생 가능한 고부하 이벤트에 대한 시스템의 내구성과 확장성을 사전에 점검하고, 필요시 성능 개선 포인트를 도출하는 것을 목적으로 한다.

## 2. 테스트 대상 선정 이유
이번 성능 테스트의 대상은 선착순 쿠폰 발급 기능이다. 
이 기능은 서비스 운영 중 다음과 같은 이유로 트래픽 집중 현상이 발생하기 쉬우며, 시스템 전반의 병목 여부를 확인하기에 적절한 테스트 대상이다.

### 2-1. 사용자 집중 트래픽 유도 특성

- 선착순 쿠폰은 제한된 수량으로 제공되기 때문에 사용자들이 특정 시점에 대거 몰려드는 경향이 있다.
- 이로 인해 짧은 시간 동안 급격한 요청이 유입되며, 이는 다른 일반 API들과는 차별화된 부하 패턴을 가진다.

### 2-2. 고동시성(High Concurrency) 요구

- 쿠폰 발급은 동일한 쿠폰에 대해 수많은 사용자들이 동시에 요청을 시도하는 구조로, 데이터 정합성과 동시성 제어가 중요한 이슈로 작용한다.
- Redis 기반의 중복 발급 방지, Kafka를 활용한 비동기 메시징 처리, Outbox 패턴 등을 통해 병렬 처리를 수행하는 로직의 안정성이 핵심이다.

### 2-3. 서비스 전체 영향도 측정 가능

- 쿠폰 발급 시 DB, Redis, Kafka, 애플리케이션 서버가 모두 관여하기 때문에 시스템 전반의 성능과 병목을 확인할 수 있다.

이러한 특성들로 인해 선착순 쿠폰 발급 기능은 실사용 시나리오를 반영한 성능 및 안정성 테스트의 대표적인 기준점이 되며, 
전체 시스템의 성능 한계를 점검하고 개선점을 도출하기에 적합하다.

## 3. 테스트 시나리오

### 3-1. Smoke Test
- 목적: 시스템이 정상적으로 동작하는지 빠르게 확인
- 가상 사용자 수: 1명
- 테스트 시간: 10초
- 특징: 기능 검증 목적의 최소 단위 테스트로, 장애 없이 쿠폰 발급 API가 호출되고 응답이 정상인지 확인

### 3-2 Load Test
- 목적: 시스템이 평균 수준의 동시 요청을 얼마나 안정적으로 처리할 수 있는지 검증
- 트래픽 구성:
  - 30초 동안 초당 1,000명까지 점진적으로 증가 (ramp-up)
  - 1분 동안 초당 1,000명 유지 (steady state)
  - 30초 동안 점진적으로 종료 (ramp-down)
- 평가 지표:
  - 95% 요청 응답시간: 1초 이하 (http_req_duration: p(95)<1000)
  - 에러율: 15% 미만 (http_req_failed: rate<0.15)
  - 성공률: 85% 이상 (success_rate: rate>0.85)

### 3-3. Stress Test
- 목적: 시스템의 최대 처리 용량과 한계 상황에서의 안정성 확인
- 트래픽 구성:
  - 매 1분 단위로 500명씩 증가하여 최대 2,000명의 동시 사용자까지 부하를 가중 
  - 각 단계는 1분간 유지하며 총 8분간 부하 지속 
  - 마지막 30초간 점진적으로 종료
- 평가 지표: Load Test와 동일한 기준 적용
- 특징: 시스템이 어느 시점에서 오류를 내기 시작하는지, 어떤 자원이 병목이 되는지를 파악하기 위한 고부하 테스트

### 3-4. Peak Test
- 목적: 짧은 시간 동안 급격한 트래픽 증가에 대한 대응 능력 검증 (실제 선착순 이벤트와 유사)
- 트래픽 구성:
  - 10초 baseline (초당 100명)
  - 20초간 급격히 증가하여 초당 2,000명 도달 
  - 10초간 다시 초당 100명으로 급감 
  - 20초간 종료
- 평가 지표: Load Test와 동일
- 특징: 스파이크 트래픽 상황 재현, Kafka 소비 지연, Outbox 상태 처리, DB 락 충돌 등 짧은 시간 내 부하 집중이 초래하는 병목 상황 분석

## 4. 테스트 환경 구성
| 구분 | 상세 내용                                      | 비고       |
| --- |--------------------------------------------|----------|
| 애플리케이션 서버 | Spring Boot(Docker, CPU 2Core, Memory 4GB) | 포트: 8080 |
| 데이터베이스 | MySQL 8.0 (Docker)                         | 포트: 3306 |
| 캐시 | Redis (Docker)                             | 포트: 6379 |
| 메시지 큐 | Kafka (Docker)                             | 포트: 9094 |
| 모니터링 도구 | Prometheus (Docker)                        | 포트: 9090 |
| 시각화 도구 | Grafana (Docker)                           | 포트: 3000 |
| 부하 테스트 도구 | k6 (Docker)                                | 포트: 6565 |

## 5. 테스트 결과

### 5-1. Load Test

<img width="1913" alt="Image" src="https://github.com/user-attachments/assets/23b80531-15f4-42f4-ad6a-7cecff633bce" />

#### 성능 지표 
| 지표 | 평균       | 중앙값      | p95 | p90 |
| --- |----------|----------|-----|-----|
| 응답 시간 | 539.90ms | 602.33ms | 1.17s | 1.02s |

#### 처리량
| 지표         | 총량    |
|------------|-------|
| 총 요청 수     | 58788 |

### 결과 분석
- 모든 요청이 실패 없이 처리됨
- 95%의 요청이 1000ms(1s) 이내에 처리되는 것을 목표로 하였으나 1.17s에 처리되어 목표치보다 약간 높음
- 응답 시간 최대 지연은 2.15s

### 5-2. Stress Test

<img width="986" alt="Image" src="https://github.com/user-attachments/assets/3f82c2bf-01ee-4494-a905-9e8da0d2c265" />
<img width="1915" alt="Image" src="https://github.com/user-attachments/assets/761c6086-b2e6-4440-bf3b-e6cad233fdb3" />

#### 성능 지표
| 지표                 | 평균       | 중앙값     | p95 | p90 |
|--------------------|----------|---------|-----|-----|
| 100명씩 단계별 증가 응답 시간 | 382.19ms | 263.93s | 1.33s | 1.05s |
| 500명씩 단계별 증가 응답 시간 | 1.85s    | 2s      | 4.26s | 3.18s |

#### 처리량
| 지표                  | 총량     |
|---------------------|--------|
| 100명씩 단계별 증가 총 요청 수 | 223816 |
| 500명씩 단계별 증가 총 요청 수 | 143116 |

### 결과 분석
- 100명씩 단계별 증가는 전체적으로 매우 안정적인 응답 성능을 보임
  - 평균 382ms, 중앙값도 263ms 수준으로 매우 빠름
  - p90/p95 구간에서도 응답 시간은 1.3초 이하로, 사용자 체감 지연도 크지 않음
- 500명씩 단계별 증가는 명확한 병목 현상 발생
  - 평균 응답 시간이 1.85초, p95는 4초 이상으로 증가 → 실사용 환경에서는 체감 지연 혹은 타임아웃 우려
  - 중앙값이 2초에 근접 → 다수의 요청에서 병목이나 큐잉 지연이 있었음을 시사
  - 병목 원인으로는 Kafka 처리 지연, DB 락 충돌, GC 일시 정지 등이 추정됨
- 500명 시나리오의 요청 수가 오히려 더 적음 
  - 이는 트래픽 자체는 더 많았지만, 요청 실패 또는 큐에 대기 중인 요청이 완료되지 못하고 중단되었을 가능성을 시사
  - 처리량 하락은 서버 자원 포화, Kafka 메시지 소비 지연, 또는 응답 시간 초과로 인한 재시도 실패 등의 가능성이 있음

### 5-3. Peak Test

<img width="1919" alt="Image" src="https://github.com/user-attachments/assets/4f93aaed-4e15-480d-905d-da620f415d29" />
<img width="1916" alt="Image" src="https://github.com/user-attachments/assets/f9e9d235-552b-4a39-bd31-dfdb40d878a5" />

#### 성능 지표
| 지표                   | 평균      | 중앙값     | p95      | p90      |
|----------------------|---------|---------|----------|----------|
| 급격히 1500명까지 증가 응답 시간 | 65.25ms | 5.05ms  | 385.97ms | 208.50ms |
| 급격히 2000명까지 증가 응답 시간 | 681.19s | 672.19s | 1.66s    | 1.50s    |

#### 처리량
| 지표                    | 총량    |
|-----------------------|-------|
| 급격히 1500명까지 증가 총 요청 수 | 25804 |
| 급격히 2000명까지 증가 총 요청 수 | 21355 |

#### 결과 분석

- 급격히 1500명까지 증가 시 
  - 평균, 중앙값 기준으로는 매우 양호 
  - 평균 65ms, 중앙값 5ms → 대부분의 요청은 초고속 응답 
  - 시스템이 높은 트래픽에도 빠르게 응답 가능함을 나타냄
- 급격히 2000명까지 증가 시 
  - 응답 시간 전반적으로 지연 
  - 평균 681ms, 중앙값 672ms → 50% 이상의 요청에서 지연 발생 
  - p95 = 1.66초 → 실사용 기준에서 사용자 체감 지연 발생 가능성 높음 
  - 처리량도 줄어드는 경향 → 포화 지점 도달
  - → 시스템의 스레드/커넥션 풀 또는 Kafka 처리량 한계 도달 가능성 있음

## 6. 권장 조치

### 6-1. Kafka Consumer 병렬성 및 처리 성능 개선
- 문제: 고부하(500명 이상 동시 요청 또는 2000명 피크 시) 상황에서 메시지 처리 지연 및 소비 병목 발생 가능성 확인됨
- 조치안:
  - Kafka 파티션 수 증가 및 컨슈머 인스턴스 수 확장 
  - 컨슈머 내부의 비즈니스 처리 로직을 비동기 또는 배치 처리로 전환하여 처리 속도 향상 
  - Batch Consumer 사용 시에도 각 메시지 개별 예외 핸들링 구조 개선 필요

### 6-2. DB 병목 완화 및 커넥션 풀 튜닝
- 문제: 응답 시간 중앙값 및 p95 값 증가와 처리량 저하가 DB 커넥션 풀 한계 또는 락 충돌에서 발생할 수 있음 
- 조치안:
  - HikariCP 등의 커넥션 풀 최대값 조정 (특히 CPU 코어 수 대비 부족하지 않게 설정)
  - 트랜잭션 범위 축소 및 DB 락 충돌이 예상되는 쿼리 최소화 
  - 선착순 쿠폰 발급 시 stock 감소 등은 Redis로 우선 선점 처리 후 DB 반영

### 6-3. Redis 락 점유 시간 최소화
- 문제: 다수 요청이 동시에 같은 쿠폰에 접근 시 Redis 분산 락 충돌 가능성 존재
- 조치안:
  - 락 범위 최소화: 필요한 핵심 구간에서만 락을 사용하고, 나머지 로직은 락 외부에서 수행 
  - Redisson 등의 라이브러리 사용 시 watchdog 시간 과도 설정 방지 
  - 가능한 경우 쿠폰 잔여 수량을 Redis ZSet 등으로 관리하고 원자 연산 활용

### 6-4. 알림 기반 모니터링 강화
- 문제: 특정 순간에만 응답 지연 및 실패 증가가 발생하므로, 지속적 관찰이 필요
- 조치안:
  - Prometheus + Grafana를 통한 응답 시간, 에러율, 처리량 대시보드 구성 
  - 1s 이상 응답 시간, Kafka 소비 지연 초과, GC 시간 증가 등에 대한 Alerting 기준 수립

